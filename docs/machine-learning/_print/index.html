<!doctype html>
<html lang="zh-cn" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.92.2" />
<link rel="canonical" type="text/html" href="https://lowerce.github.io/docs/machine-learning/">
<link rel="alternate" type="application/rss&#43;xml" href="https://lowerce.github.io/docs/machine-learning/index.xml">
<meta name="robots" content="noindex, nofollow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>机器学习 | Lowerce&#39;s Wiki Blog</title>
<meta name="description" content="机器学习的相关笔记.
">
<meta property="og:title" content="机器学习" />
<meta property="og:description" content="机器学习的相关笔记.
" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://lowerce.github.io/docs/machine-learning/" /><meta property="og:site_name" content="Lowerce&#39;s Wiki Blog" />

<meta itemprop="name" content="机器学习">
<meta itemprop="description" content="机器学习的相关笔记.
"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="机器学习"/>
<meta name="twitter:description" content="机器学习的相关笔记.
"/>




<link rel="preload" href="/scss/main.min.704093cd1a56f37fd00dc35c7125fced09d88d60c92d59965b30c8c0eeef1cd5.css" as="style">
<link href="/scss/main.min.704093cd1a56f37fd00dc35c7125fced09d88d60c92d59965b30c8c0eeef1cd5.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-JK76XTWHST"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-JK76XTWHST', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
		<span class="navbar-logo"></span><span class="text-uppercase font-weight-bold">Lowerce&#39;s Wiki Blog</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/about/" ><span>About</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link active" href="/docs/" ><span class="active">Notes</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/blog/" ><span>Blog</span></a>
			</li>
			
			
			
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block"><input type="search" class="form-control td-search-input" placeholder="&#xf002; 站内搜索…" aria-label="站内搜索…" autocomplete="off">
</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href="#" onclick="print();return false;">点击此处打印</a>.
</p><p>
<a href="/docs/machine-learning/">返回本页常规视图</a>.
</p>
</div>



<h1 class="title">机器学习</h1>
<div class="lead">机器学习的相关笔记.</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-ec021ae621f53763870f7ceb22a58b6f">李宏毅机器学习课程</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-ec021ae621f53763870f7ceb22a58b6f">1 - 李宏毅机器学习课程</h1>
    
	<p>此文是根据李宏毅2021年春季的机器学习课程撰写。李宏毅机器学习课程的特点是对理论理解的剖析非常深入同时又不失在实际训练过程中的trick教学。</p>
<h2 id="1-机器学习general-guidence">1. 机器学习general guidence</h2>
<p><img src="https://img.tujidu.com/image/6216449b04c46.jpg" alt="机器学习general guidence"></p>
<h2 id="2-调参trick">2. 调参trick</h2>
<h3 id="1-local-minima局部最小值and-saddle-point鞍点">1. local minima（局部最小值）and saddle point（鞍点）</h3>
<p><strong>Hessian Matrix</strong> - 其实就是二阶导 在一阶导数消失的时候通过二阶导来决定下一步行进的方向</p>
<p>H正定时（Hessian Matrix 所有特征值为正）说明遇到 local minima</p>
<p>H正负不定（Hessian Matrix 特征值有正有负）说明遇到 saddle point</p>
<p>向沿H特征向量的方向更新参数</p>
<h3 id="2-batch-size-and-momentum">2. batch size and momentum</h3>
<p><strong>batch size大小的优劣</strong></p>
<p><img src="https://img.tujidu.com/image/621644e069277.jpg" alt="batch size"></p>
<p><strong>由1、2得出的conclusion</strong></p>
<p><img src="https://img.tujidu.com/image/6216451f17749.jpg" alt="conclusin of 1 and 2"></p>
<h3 id="3-adaptive-learning-rate">3. Adaptive Learning Rate</h3>
<p><strong>sigma</strong></p>
<p>Root Mean Square &ndash;&gt; RMSProp &ndash;&gt; Adam(RMSProp + Momentum)</p>
<p><strong>eta</strong></p>
<p>Learning Rate Scheduling: Learing Rate Decay and Warm Up</p>
<p><strong>Optimizer总结</strong></p>
<p><img src="https://img.tujidu.com/image/62164545ae1f4.jpg" alt="Optimization Summary"></p>
<h3 id="4-loss-function">4. Loss function</h3>
<p>Cross-entropy 如何优于 Mean Square Error (MSE)？</p>
<p>从error surface的角度来看 Cross-entropy 的梯度变化更平缓 &ndash;&gt; 更好 train</p>
<h3 id="5-batch-normalization">5. Batch Normalization</h3>
<p>Feature Normalization - 对所有样本的每一个维度（dimension）作 normalization（减均值、除方差）</p>
<p>可以对每一层的输出（激活函数前后影响不大）作上述 Featurn Normalization</p>
<p>归根结底让整个 error surface 不那么崎岖（还有各种Normalization的方法）</p>
<h2 id="3-cnn">3. CNN</h2>
<p>在图像感知的问题中使用</p>
<p>stride 迈步步长 padding 越界填充</p>
<p>Receptive field &ndash;&gt; neutrons &ndash;&gt; shared parameters</p>
<p>filters &ndash;&gt; Feature Map</p>
<p><strong>两种看待CNN所做事情的角度</strong></p>
<p><img src="https://img.tujidu.com/image/6216456fddf44.jpg" alt="两个故事"></p>
<p>Pooling - subsampling  比较典型的 Max Pooling</p>
<p>Pooling不是必要的</p>
<p><strong>CNN的标准流程</strong></p>
<p><img src="https://img.tujidu.com/image/62164593a3514.jpg" alt="典型CNN流程"></p>
<h2 id="4-self-attention">4. Self-attention</h2>
<p>Sequence(vector set) input 考虑整个input sequence的资讯</p>
<p>《Attention is all you need》</p>
<p><strong>Self-attention的运行方式</strong></p>
<p><img src="https://img.tujidu.com/image/621645bb560ed.jpg" alt="self attention运作机制"></p>
<p><strong>Multi-head Self-attention</strong></p>
<p><img src="https://img.tujidu.com/image/621645d7cbaab.jpg" alt="multi-head self attention"></p>
<p><strong>Position Encoding</strong></p>
<p><img src="https://img.tujidu.com/image/621645fada77f.jpg" alt="position encoding"></p>
<p>Self-attention可以视作可调感知域的<strong>CNN</strong>（在数据量足够大时效果要好于CNN） CNN属于简化版的Self-attention</p>
<p>Self-attention比起<strong>RNN</strong>更加不受输入vector之间距离的影响</p>
<h2 id="5-transformer-seq2seq">5. Transformer (Seq2Seq)</h2>
<p>语音辨识</p>
<p>Encoder + Decoder</p>
<h3 id="encoder">Encoder</h3>
<p><strong>Encoder block的构成</strong></p>
<p><img src="https://img.tujidu.com/image/62164621bfb72.jpg" alt="one block of Encoder"></p>
<p><strong>Encoder的结构</strong></p>
<p><img src="https://img.tujidu.com/image/6216464cb6e22.jpg" alt="Encoder"></p>
<h3 id="decoder">Decoder</h3>
<p>分为 Autoregressive 和 Non- Autoregressive</p>
<p><img src="https://img.tujidu.com/image/6216467f273cf.jpg" alt="对比"></p>
<p>下面以Autoregressive为例概述Decoder的组成结构</p>
<p><strong>Masked Self-attention</strong></p>
<p>显然在Decoder中上一个的输出作为下一个的输入，输入一个一个依次产生，无法像Self-attention那样直接考虑所有的资讯</p>
<p><img src="https://img.tujidu.com/image/621646b23eeab.jpg" alt="Masked Self-attention"></p>
<p><strong>Cross attention</strong></p>
<p><img src="https://img.tujidu.com/image/621646d66ca74.jpg" alt="Cross attention"></p>
<p><strong>Decoder的结构（Encoder and Decoder）</strong></p>
<p><img src="https://img.tujidu.com/image/621646f54324e.jpg" alt="Decoder"></p>
<h3 id="其它的seq2seq架构">其它的Seq2Seq架构</h3>
<p>Copy mechanism: Pointer Network</p>
<p>Guided Attention:  Monotonic Attention、 Location-aware attention</p>
<h3 id="评价方法">评价方法</h3>
<p>BLUE score</p>
<p>但BLUE难以用于optimuze，对于不知道如何optimize的问题可以使用<strong>RL</strong>解决</p>
<h3 id="exposure-bias">exposure bias</h3>
<p>Scheduled Sampling来防止在teacher forcing下可能出现的“一步错步步错”的问题</p>
<h2 id="6-gan">6. GAN</h2>
<p>输出一种分布 <strong>Generator-生成</strong></p>
<p><strong>Discriminator</strong>（判别Generator生成的优劣）</p>
<p>D将G的生成集和训练集分别label后进行训练以期分辨G的生成和自然数据的差异(real or fake，real打分更高)；G将生成接到D上让D打分 以此作为loss 来更新G的参数</p>
<p>轮流固定G和D，训练D和G</p>
<h3 id="训练trick">训练trick</h3>
<p>D存在的意义是在无法或者不容易计算生成数据分布与自然数据分布的divergence的情况下给出loss使G能够train起来，divergence的选择（参见f-GAN文章）决定了D的objective function。</p>
<p>JS divergence 不适合区分两个分布没有重叠(overlap)的情况，而在高维空间中不同分布图像的overlap很少；Wasserstein distance适于计算两个分布之间的距离（WGAN）</p>
<p>未完待续&hellip;</p>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/Lowerce" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2023 Lowerce 保留所有权利</small>
        
	
		<p class="mt-2"><a href="/about/">About Lowerce</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
    integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
    integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA=="
    crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>


















<script src="/js/main.min.ad402bfdb1ac8104d66668e601ee54c4f539eb3e53a1595e2755d0448cc75f6d.js" integrity="sha256-rUAr/bGsgQTWZmjmAe5UxPU56z5ToVleJ1XQRIzHX20=" crossorigin="anonymous"></script>




  </body>
</html>
